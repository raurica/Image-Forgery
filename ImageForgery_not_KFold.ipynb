{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageForgery_not_KFold.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZ0aCfRfvrI5IF34x2v3ml",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raurica/Image-Forgery/blob/main/ImageForgery_not_KFold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CfQUO_RSuXiP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os, shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sn; sn.set(font_scale=1.4)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dense\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "bgx_gzwcudWE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def tf_seed(seed=0):\n",
        "  np.random.seed(seed)  # numpy seed\n",
        "  tf.random.set_seed(seed)  # tensorflow seed\n",
        "  random.seed(seed)  # random seed\n",
        "  os.environ['TF_DETERMINISTIC_OPS'] = \"1\"\n",
        "  os.environ['TF_CUDNN_DETERMINISM'] = \"1\"\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "tf_seed()"
      ],
      "metadata": {
        "id": "FbPYQcFNvfGn"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading the dataset"
      ],
      "metadata": {
        "id": "P4kCo3iqxJOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"MICC-F220\" #@param [\"MICC-F220\", \"MICC-F600\", \"MICC-F2000\", \"Merged datasets\"]\n",
        "id_data = ['1pL6W3mN931TmmaCtMZsR0z1YuVfkvH4J','1JDz-suK2Qy0HDTXzq8XPDRs5QmRX9e4s','1G5XjcONn5-TK5h_S3sPNwYxDICNWZ-8h']\n",
        "names_dataset = [\"MICC-F220\", \"MICC-F600\", \"MICC-F2000\"]\n",
        "\n",
        "if dataset=='MICC-F220':\n",
        "  fileId = drive.CreateFile({'id':id_data[0]})\n",
        "elif dataset=='MICC-F600':\n",
        "  fileId = drive.CreateFile({'id':id_data[1]})\n",
        "elif dataset=='MICC-F2000':\n",
        "  fileId = drive.CreateFile({'id':id_data[2]})\n",
        "elif dataset=='Merged datasets':\n",
        "  for i in range(len(id_data)):\n",
        "    fileId = drive.CreateFile({'id':id_data[i]})\n",
        "    fileId.GetContentFile(fileId['title'])\n",
        "    name_ds = names_dataset[i]+'.zip'\n",
        "    print(name_ds)\n",
        "    #!unzip -q name_ds\n",
        "    ZipFile(names_dataset[i]+'.zip').extractall('/content/')\n",
        "\n",
        "\n",
        "  # folder in which all the content will be merged\n",
        "  merge_folder = [\"/content/Datasets/test_train_images/original\",\n",
        "                \"/content/Datasets/test_train_images/tampered\",\n",
        "                \"/content/Datasets/validation_images/original\",\n",
        "                \"/content/Datasets/validation_images/tampered\"]\n",
        "\n",
        "  if not os.path.exists('/content/Datasets/'):\n",
        "    os.mkdir('/content/Datasets/')\n",
        "    os.mkdir('/content/Datasets/test_train_images/')\n",
        "    os.mkdir('/content/Datasets/validation_images/')\n",
        "\n",
        "    for folder in merge_folder:\n",
        "      if not os.path.exists(folder):\n",
        "        os.mkdir(folder)\n",
        "\n",
        "  # current folder path\n",
        "  current_folder = os.getcwd() \n",
        "    \n",
        "  # list of folders to be merged\n",
        "  list_dir = [['/content/MICC-F220/test_train_images/original', '/content/MICC-F600/test_train_images/original','/content/MICC-F2000/test_train_images/original'], \n",
        "              ['/content/MICC-F220/test_train_images/tampered', '/content/MICC-F600/test_train_images/tampered','/content/MICC-F2000/test_train_images/tampered'],\n",
        "              ['/content/MICC-F220/validation_images/original', '/content/MICC-F600/validation_images/original','/content/MICC-F2000/validation_images/original'],\n",
        "              ['/content/MICC-F220/validation_images/tampered', '/content/MICC-F600/validation_images/tampered','/content/MICC-F2000/validation_images/tampered']]\n",
        "    \n",
        "  # enumerate on list_dir to get the content of all the folders ans store it in a dictionary\n",
        "  content_list = {}\n",
        "  for i in range(len(merge_folder)):\n",
        "    for index, val in enumerate(list_dir[i]):\n",
        "        path = os.path.join(current_folder, val)\n",
        "        content_list[ list_dir[i][index] ] = os.listdir(path)\n",
        "\n",
        "    # Function to create new folder if not exists\n",
        "    def make_new_folder(folder_name, parent_folder_path):\n",
        "        path = os.path.join(parent_folder_path, folder_name)\n",
        "        try: \n",
        "            mode = 0o777\n",
        "            os.mkdir(path, mode) \n",
        "        except OSError as error: \n",
        "            print(error)\n",
        "              \n",
        "\n",
        "      \n",
        "    # merge_folder path - current_folder + merge_folder\n",
        "    merge_folder_path = os.path.join(current_folder, merge_folder[i]) \n",
        "      \n",
        "    # create merge_folder if not exists\n",
        "    make_new_folder(merge_folder[i], current_folder)\n",
        "\n",
        "\n",
        "    # loop through the list of folders\n",
        "    for sub_dir in content_list:\n",
        "        # loop through the contents of the list of folders\n",
        "        for contents in content_list[sub_dir]:\n",
        "      \n",
        "            # make the path of the content to move \n",
        "            path_to_content = sub_dir + \"/\" + contents  \n",
        "            if os.path.exists(path_to_content):\n",
        "              # make the path with the current folder\n",
        "              dir_to_move = os.path.join(current_folder, path_to_content )\n",
        "              filename = os.path.basename(path_to_content)\n",
        "              dest = os.path.join(merge_folder_path,filename)\n",
        "              shutil.move(dir_to_move, dest)\n",
        "  for ds in names_dataset:    \n",
        "    shutil.rmtree('/content/'+ds)   \n",
        "\n",
        "\n",
        "if not dataset=='Merged datasets':\n",
        "  fileId.GetContentFile(fileId['title'])\n",
        "  ZipFile(dataset+'.zip').extractall('/content/')\n",
        "\n",
        "print('Uploaded {}, id {}'.format(fileId['title'],fileId['id']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e1s5BjHvgPJ",
        "outputId": "0366e2f5-fa87-43bf-abed-a132c3cabcc7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded MICC-F220.zip, id 1pL6W3mN931TmmaCtMZsR0z1YuVfkvH4J\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Main variables"
      ],
      "metadata": {
        "id": "yWBgSAogxUvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15 #@param [\"15\", \"25\", \"35\", \"50\", \"75\", \"100\"] {type:\"raw\"}\n",
        "BATCH_SIZE = 16 #@param {type:\"integer\"}\n",
        "\n",
        "IMAGE_SIZE = (224,224)"
      ],
      "metadata": {
        "id": "8KxtKcnYvuYE"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating labels"
      ],
      "metadata": {
        "id": "ujCVC3YLxbAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['original','tampered']\n",
        "class_name_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "nb_classes = len(class_names)\n",
        "print(class_name_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDdsTEFLvxf7",
        "outputId": "f3b39271-f10b-4a57-b6d3-3dedd8854350"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'original': 0, 'tampered': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load data"
      ],
      "metadata": {
        "id": "9ldAyQenxiQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "\n",
        "    tf_seed()\n",
        "\n",
        "    if not dataset=='Merged datasets':\n",
        "      DIRECTORY = r\"/content/\"+dataset\n",
        "    else:\n",
        "      DIRECTORY = r\"/content/Datasets\"\n",
        "\n",
        "    CATEGORY = [\"test_train_images\",\"validation_images\"]\n",
        "    \n",
        "    output = []\n",
        "    \n",
        "    for category in CATEGORY:\n",
        "        path = os.path.join(DIRECTORY, category)\n",
        "        images = []\n",
        "        labels = []\n",
        "        \n",
        "        print(\"Loading {}\".format(category))\n",
        "        \n",
        "        for folder in os.listdir(path):\n",
        "          if not folder.startswith('.'):           \n",
        "            label = class_name_label[folder]\n",
        "            \n",
        "            for file in os.listdir(os.path.join(path, folder)): \n",
        "                \n",
        "                img_path = os.path.join(os.path.join(path,folder),file)\n",
        "                print(img_path)\n",
        "                image = cv2.imread(img_path)\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                image = cv2.resize(image, IMAGE_SIZE)\n",
        "                \n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                \n",
        "        images = np.array(images, dtype=\"float32\")\n",
        "        labels = np.array(labels, dtype=\"float32\")\n",
        "    return images,labels #output"
      ],
      "metadata": {
        "id": "dLQ_jUCGv0QP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_plot = False #@param {type:\"boolean\"}\n",
        "\n",
        "def plot_accuracy_loss(H):\n",
        "\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  fig=plt.figure(figsize=(12,7))\n",
        "\n",
        "  new_epochs=len(H.history['loss'])\n",
        "  plt.plot(np.arange(0, new_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, new_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(np.arange(0, new_epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, new_epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend(loc=\"lower left\")\n",
        "\n",
        "  if save_plot==True:\n",
        "    plt.savefig('ImageForgery_'+dataset+'_'+str(EPOCHS)+'ep.jpg')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "bl20pVZ1zPLY"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = load_data()\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SM2Rqawv25T",
        "outputId": "3c8b308b-1704-4664-81f4-477be4441e97"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test_train_images\n",
            "/content/MICC-F220/test_train_images/original/CRW_4810_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1568_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4838_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4836_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1572_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1561_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4840_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1570_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1557_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1580_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4830_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1575_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1549_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4833_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4827_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4835_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4852_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4848_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1567_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1542_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4831_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4814_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4901_JFR_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSCF3_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4822_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4841_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1550_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4853_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSCF2_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4809_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4818_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1540_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1573_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1581_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1554_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1576_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1595_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSCF1_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4842_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1535_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4820_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4817_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_0812_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4823_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1546_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4829_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4839_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4815_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4821_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4834_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_0535_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1539_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/CRW_4825_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1538_scale.jpg\n",
            "/content/MICC-F220/test_train_images/original/DSC_1571_scale.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4853tamp237.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4853tamp37.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1540tamp1.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0535tamp237.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0535tamp134.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0812tamp1.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0535tamp27.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0535tamp131.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0535tamp25.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4853tamp1.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4853tamp134.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4901_JFRtamp132.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0812tamp132.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0812tamp134.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4901_JFRtamp134.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1535tamp237.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0812tamp133.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0535tamp176.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0812tamp37.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0535tamp133.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4853tamp131.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1535tamp25.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1535tamp131.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0535tamp37.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4901_JFRtamp25.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1535tamp132.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4853tamp133.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1535tamp133.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1540tamp131.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0812tamp237.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1535tamp37.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0812tamp176.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4901_JFRtamp27.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0812tamp25.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4853tamp25.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4901_JFRtamp176.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4901_JFRtamp1.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1535tamp27.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4901_JFRtamp37.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4853tamp132.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1535tamp134.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4901_JFRtamp131.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4901_JFRtamp237.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0535tamp1.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4853tamp27.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4901_JFRtamp133.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1540tamp25.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1535tamp1.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0535tamp132.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1535tamp176.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1540tamp37.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0812tamp131.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_1540tamp27.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/DSC_0812tamp27.jpg\n",
            "/content/MICC-F220/test_train_images/tampered/CRW_4853tamp176.jpg\n",
            "Loading validation_images\n",
            "/content/MICC-F220/validation_images/original/P1000318_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF13_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/P1000472_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/P1000231_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN2327_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF15_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN2321_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN45_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN2324_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_63_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/IMG_32_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN48_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/P1000213_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF1853_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_71_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN2328_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN49_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN47_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_72_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN2326_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN2323_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN2322_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF10_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_66_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF18_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_69_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/P1000293_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF12_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN43_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/P1000553_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF2059_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF14_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF16_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN50_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_61_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN2325_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_68_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF5_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF9_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_64_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN41_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN46_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/P1000528_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF6_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF8_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_65_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/nikon_7_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_70_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/sony_67_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN2320_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF4_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN2329_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF7_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCF11_scale.jpg\n",
            "/content/MICC-F220/validation_images/original/DSCN44_scale.jpg\n",
            "/content/MICC-F220/validation_images/tampered/sony_61tamp1.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN41tamp25.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1568tamp37.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN41tamp1.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1568tamp176.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCF8tamp37.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1568tamp25.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN45tamp132.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCF8tamp25.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1540tamp237.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCF8tamp133.jpg\n",
            "/content/MICC-F220/validation_images/tampered/sony_61tamp132.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN45tamp1.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN45tamp131.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN41tamp134.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCF8tamp237.jpg\n",
            "/content/MICC-F220/validation_images/tampered/sony_61tamp37.jpg\n",
            "/content/MICC-F220/validation_images/tampered/sony_61tamp176.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1568tamp27.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1568tamp131.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCF8tamp132.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN45tamp27.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCF8tamp131.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN45tamp237.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN41tamp176.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCF8tamp27.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1568tamp132.jpg\n",
            "/content/MICC-F220/validation_images/tampered/sony_61tamp237.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN41tamp131.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1540tamp132.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN41tamp27.jpg\n",
            "/content/MICC-F220/validation_images/tampered/sony_61tamp25.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN41tamp133.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN45tamp176.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1540tamp133.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN41tamp132.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCF8tamp134.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1568tamp133.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCF8tamp176.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1568tamp1.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1568tamp237.jpg\n",
            "/content/MICC-F220/validation_images/tampered/sony_61tamp133.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN45tamp37.jpg\n",
            "/content/MICC-F220/validation_images/tampered/sony_61tamp134.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN45tamp25.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN45tamp133.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN45tamp134.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1568tamp134.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN41tamp37.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1540tamp176.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCN41tamp237.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSCF8tamp1.jpg\n",
            "/content/MICC-F220/validation_images/tampered/DSC_1540tamp134.jpg\n",
            "/content/MICC-F220/validation_images/tampered/sony_61tamp27.jpg\n",
            "/content/MICC-F220/validation_images/tampered/sony_61tamp131.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing"
      ],
      "metadata": {
        "id": "4Smsob5Yxmka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255"
      ],
      "metadata": {
        "id": "rN2Z6qicv5kj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model and training"
      ],
      "metadata": {
        "id": "gLg2UXbmxrCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, psutil\n",
        "\n",
        "class MemoryUsage(keras.callbacks.Callback):\n",
        "   def __init__(self):\n",
        "      # setting device on GPU if available, else CPU\n",
        "      self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "      print('Using device for training:', self.device)\n",
        "      self.max_RAM=[]\n",
        "      self.max_GPU=[]\n",
        "\n",
        "   def get_memory_usage(self):\n",
        "      gpu_dict = tf.config.experimental.get_memory_info('GPU:0')\n",
        "      print('\\n GPU memory details [current: {} gb, peak: {} gb]'.format(\n",
        "          float(gpu_dict['current']) / (1024 ** 3), \n",
        "          float(gpu_dict['peak']) / (1024 ** 3)))\n",
        "   \n",
        "   def get_size(self, byte, suffix=\"GB\"):\n",
        "    factor = 1024\n",
        "    \n",
        "    for unit in [\"\", \"K\", \"M\", \"GB\", \"T\", \"P\"]:\n",
        "        if byte < factor:\n",
        "            return f\"{byte:.2f} GB\"\n",
        "        byte /= factor\n",
        "\n",
        "   def on_train_end(self, epoch, logs=None):\n",
        "      i=np.argmax(self.max_RAM)\n",
        "      j=np.argmin(self.max_RAM)\n",
        "      self.get_memory_usage()\n",
        "      print(\"MAX RAM USAGE: %s / %s (%s)\" % (self.get_size(self.max_RAM[i][0]), self.get_size(self.max_RAM[i][1]), str(self.max_RAM[i][2]) + \"%\" ))\n",
        "    \n",
        "   def on_epoch_end(self,epoch,logs=None):\n",
        "      svmem = psutil.virtual_memory()\n",
        "      self.max_RAM.append((svmem.active, svmem.total, svmem.percent))\n",
        "      #self.get_memory_usage()\n",
        "      "
      ],
      "metadata": {
        "id": "m3Z7Yrni28p5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = True #@param {type:\"boolean\"}\n",
        "\n",
        "tf_seed()\n",
        "\n",
        "#============ DEFINE MODEL ===============\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, 1, activation='relu', input_shape=(224,224,3)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3),1, activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(128, (3,3),1, activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(256, (3,3),1, activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Conv2D(512, (3,3),1, activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#============ TRAINING MODEL ===============\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "model.summary()\n",
        "\n",
        "H = model.fit(train_images, train_labels, \n",
        "                    batch_size=BATCH_SIZE, \n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(test_images,test_labels),\n",
        "                    #callbacks = [memory_usage, callback_early_stopping],\n",
        "                    shuffle=True,\n",
        "                    verbose=1\n",
        "                    )\n",
        "\n",
        "#============ EVALUATE MODEL ===============\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(\"TRAINING TIME\",\"--- %s seconds ---\" % round((time.time() - start_time),3))\n",
        "\n",
        "\n",
        "#============ SAVING MODEL ===============\n",
        "\n",
        "if save_model==True: model.save('ImageForgery_'+dataset+'_'+str(EPOCHS)+'ep.h5') "
      ],
      "metadata": {
        "id": "2ZzFyUSCv7rl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a40bee-afac-4daf-f7be-2c5c2cd66d1f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] compiling model...\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 224, 224, 16)      64        \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 112, 112, 16)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 110, 110, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 55, 55, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 53, 53, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 26, 26, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 12, 12, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 10, 10, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 5, 5, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 3, 3, 512)         1180160   \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 1, 1, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,573,410\n",
            "Trainable params: 1,573,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "6/6 [==============================] - 21s 3s/step - loss: 0.6996 - accuracy: 0.5227 - val_loss: 0.6960 - val_accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "6/6 [==============================] - 5s 759ms/step - loss: 0.6948 - accuracy: 0.5341 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "6/6 [==============================] - 4s 726ms/step - loss: 0.6939 - accuracy: 0.4773 - val_loss: 0.6864 - val_accuracy: 0.5909\n",
            "Epoch 4/15\n",
            "6/6 [==============================] - 5s 762ms/step - loss: 0.6747 - accuracy: 0.6023 - val_loss: 0.6931 - val_accuracy: 0.4545\n",
            "Epoch 5/15\n",
            "6/6 [==============================] - 5s 775ms/step - loss: 0.6264 - accuracy: 0.6477 - val_loss: 0.8593 - val_accuracy: 0.4091\n",
            "Epoch 6/15\n",
            "6/6 [==============================] - 5s 774ms/step - loss: 0.5560 - accuracy: 0.7045 - val_loss: 0.6416 - val_accuracy: 0.5909\n",
            "Epoch 7/15\n",
            "6/6 [==============================] - 4s 756ms/step - loss: 0.4271 - accuracy: 0.8409 - val_loss: 0.6894 - val_accuracy: 0.6364\n",
            "Epoch 8/15\n",
            "6/6 [==============================] - 5s 777ms/step - loss: 0.4450 - accuracy: 0.7614 - val_loss: 0.8300 - val_accuracy: 0.5455\n",
            "Epoch 9/15\n",
            "6/6 [==============================] - 5s 759ms/step - loss: 0.4121 - accuracy: 0.8068 - val_loss: 0.3977 - val_accuracy: 0.7727\n",
            "Epoch 10/15\n",
            "6/6 [==============================] - 5s 766ms/step - loss: 0.2595 - accuracy: 0.9205 - val_loss: 0.7257 - val_accuracy: 0.8636\n",
            "Epoch 11/15\n",
            "6/6 [==============================] - 5s 782ms/step - loss: 0.2390 - accuracy: 0.8977 - val_loss: 0.7576 - val_accuracy: 0.9545\n",
            "Epoch 12/15\n",
            "6/6 [==============================] - 5s 786ms/step - loss: 0.1995 - accuracy: 0.9091 - val_loss: 0.9478 - val_accuracy: 0.9091\n",
            "Epoch 13/15\n",
            "6/6 [==============================] - 5s 784ms/step - loss: 0.1841 - accuracy: 0.9432 - val_loss: 0.7971 - val_accuracy: 0.9545\n",
            "Epoch 14/15\n",
            "6/6 [==============================] - 5s 770ms/step - loss: 0.1637 - accuracy: 0.9545 - val_loss: 0.6657 - val_accuracy: 0.9545\n",
            "Epoch 15/15\n",
            "6/6 [==============================] - 5s 779ms/step - loss: 0.1742 - accuracy: 0.9545 - val_loss: 0.7300 - val_accuracy: 0.9545\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.7300 - accuracy: 0.9545\n",
            "TRAINING TIME --- 144.738 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracy_loss(H)"
      ],
      "metadata": {
        "id": "6TnMe7k83JOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, accuracy_score\n",
        "import itertools\n",
        "from itertools import cycle\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "pred_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(classification_report(test_labels, pred_labels))\n",
        "\n",
        "print(confusion_matrix(test_labels,pred_labels))\n",
        "tn, fp, fn, tp = confusion_matrix(list(test_labels), list(pred_labels), labels=[0, 1]).ravel()\n",
        "\n",
        "print('TP', tp,'\\nTN', tn,'\\nFP', fp,'\\nFN', fn)\n",
        "\n",
        "print('\\nTPR', round(tp/(tp+fn),4))\n",
        "print('FNR', round(fn/(fn+tp),4))\n",
        "print('FPR', round(fp/(fp+tn),4))\n",
        "print('TNR', round(tn/(tn+fp),4))\n",
        "print('\\nAccuracy:',round(accuracy_score(test_labels, pred_labels),4))\n",
        "print('F1-score', round(2*tp/(2*tp+fp+fn),3))\n"
      ],
      "metadata": {
        "id": "YCWgS_UDO4O8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0223ea75-ab4f-4801-c837-353c8fcffac3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.91      0.93       138\n",
            "         1.0       0.88      0.93      0.90       101\n",
            "\n",
            "    accuracy                           0.92       239\n",
            "   macro avg       0.91      0.92      0.91       239\n",
            "weighted avg       0.92      0.92      0.92       239\n",
            "\n",
            "[[125  13]\n",
            " [  7  94]]\n",
            "\n",
            "True Positive 94 \n",
            "True Negative 125 \n",
            "False Positive 13 \n",
            "False Negative 7\n",
            "\n",
            "TPR 0.9307\n",
            "FNR 0.0693\n",
            "FPR 0.0942\n",
            "TNR 0.9058\n",
            "\n",
            "Accuracy: 0.9163\n",
            "F1-score 0.904\n"
          ]
        }
      ]
    }
  ]
}